{"componentChunkName":"component---node-modules-narative-gatsby-theme-novela-src-templates-article-template-tsx","path":"/Constructing-a-complex-dictionary-of-base-and-derived-class-using-the-same-code","result":{"data":{"allSite":{"edges":[{"node":{"siteMetadata":{"name":"Mitesh Shah's Blog"}}}]}},"pageContext":{"article":{"id":"d525c443-3d53-5eb6-a755-6f6f1805420b","slug":"/Constructing-a-complex-dictionary-of-base-and-derived-class-using-the-same-code","secret":false,"title":"Constructing a complex dictionary of base and derived class using the same code","author":"Mitesh Shah","date":"August 13th, 2020","dateForSEO":"2020-08-13T00:00:00.000Z","timeToRead":2,"excerpt":"An interesting problem I encountered while working and an equally interesting solution suggested to me. How to use the same code to create complex data structure of two different classes.","subscription":true,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Constructing a complex dictionary of base and derived class using the same code\",\n  \"author\": \"Mitesh Shah\",\n  \"date\": \"2020-08-13T00:00:00.000Z\",\n  \"hero\": \"./images/hero.jpg\",\n  \"excerpt\": \"An interesting problem I encountered while working and an equally interesting solution suggested to me. How to use the same code to create complex data structure of two different classes.\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Okay, really complex title aside, I\\u2019ll try to explain the problem I had and the interesting way I found to solve it. This may not be the best or the most optimized way, but I really liked this solution and would like to share it.\"), mdx(\"p\", null, \"Also, although I do prefer Python, this post is in C#, since that was the language I encountered this problem in.\"), mdx(\"p\", null, \"So here is the problem. Say we have two C# Classes\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-csharp\"\n  }), \"public class BaseClass\\n{\\n    public string SomeProperties { get; set; }\\n}\\n\\npublic class DerivedClass : BaseClass\\n{\\n    public string SomeOtherProperties { get; set; }\\n}\\n\")), mdx(\"p\", null, \"I wanted to construct a Dictionary of these classes like \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Dictionary<string, BaseClass>\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Dictionary<string, DerivedClass>\"), \" at two very different places. The construction of each dictionary element was not that trivial due to the inherent complexity of filling the properties for both the classes. Here is an example of how one of the dictionaries was being created:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-csharp\"\n  }), \"// For the base class\\nvar map = new Dictionary<string, BaseClass>();\\nforeach(var someProperty in someList)\\n{\\n    var baseElement = new BaseClass(someProperty);\\n    map[someProperty] = baseElement;\\n}\\n\\nforeach(var dependency in dependencyList)\\n{\\n    map[dependency.To] = map[dependency.From]\\n}\\n\\n// For the derived class\\nvar map = new Dictionary<string, DerivedClass>();\\nforeach(var someProperty in someList)\\n{\\n    // someOtherProperty comes from somewhere else\\n    var derivedElement = new DerivedClass(someProperty, someOtherProperty);\\n    map[someProperty] = derivedElement;\\n}\\n\\nforeach(var dependency in dependencyList)\\n{\\n    map[dependency.To] = map[dependency.From]\\n}\\n\")), mdx(\"p\", null, \"As you can see, there is a lot of logic repeating since the properties that were created for the base class were also created for the derived class, but when we create the DerivedClass object, new properties were also to be added to those object. Both the objects differ in how they are constructed but the way the map is created is similar. I wanted a way to reuse these for loops instead of writing them for both \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"BaseClass\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"DerivedClass\"), \" and other classes that might inherit from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"BaseClass\"), \" later.\"), mdx(\"p\", null, \"My basic idea was to use a Template method like this.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-csharp\"\n  }), \"public Dictionary<string, <T>> CreateDictionary(parameters)\\n{\\n    while(someConditionOnParameters)\\n    {\\n        if(T is BaseClass)\\n        {\\n            // Base class object creation code\\n        }\\n        else if(T is DerivedClass)\\n        {\\n            // Derived class object creation code\\n        }\\n        // repeated dictionary creation code\\n    }\\n}\\n\")), mdx(\"p\", null, \"The other problem that I encounter here in was the arguments to this method. When we create the BaseClass object, I require fewer properties but when I created DerivedClass object, I require more properties and hence the number and type of arguments couldn\\u2019t be fixed. Of course, I can set/pass them as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"null\"), \" and ignore when not needed, but that didn\\u2019t feel like a tidy solution to me. Plus later on, when we derive a new class from BaseClass, again the signature of method changes which might break a few things here and there.\"), mdx(\"p\", null, \"That\\u2019s when I was suggested the interesting solution to this problem, the one I am going to share now. We keep one function that creates this dictionary but rather than passing the parameters to create the objects, we pass a function that creates those objects for us. For example when we want to create the BaseClass dictionary, we can pass a function that creates the base class object and so on. This way this method can be extensible for any classes that derive from future as well. Here is a dummy code to show how that method might look like\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-csharp\"\n  }), \"public Dictionary<string, BaseClass> CreateDictionary(DataObject requiredData, Func<Data, BaseClass> objectCreator)\\n{\\n    var map = new Dictionary<string, BaseClass>();\\n    foreach(Data propertyValues in requiredData.data)\\n    {\\n        var element = objectCreator(Data);\\n    }\\n    foreach(var dependency in requiredData.dependencies)\\n    {\\n        map[dependency.To] = dependency.From;\\n    }\\n}\\n\")), mdx(\"p\", null, \"Now when I want to create the base class dictionary, I can call it like:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-csharp\"\n  }), \"var map = CreateDictionary(requiredData, x => \\n{\\n    return new BaseClass(x.somePropertyValue);\\n});\\n\")), mdx(\"p\", null, \"Or if I want the derived class dictionary, like this:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-csharp\",\n    \"metastring\": \"live\",\n    \"live\": true\n  }), \"var map = CreateDictionary(requiredData, x => \\n{\\n    return new DerivedClass(x.SomePropertyValue, someOtherPropertyValue);\\n});\\n\")), mdx(\"p\", null, \"I really loved this solution, its nifty and useful and this didnt come to my mind easily.\"), mdx(\"h3\", {\n    \"id\": \"closing-thoughts\"\n  }, \"Closing Thoughts\"), mdx(\"p\", null, \"I know this is a really specific and weird problem to encounter, and some constraints of why this solution was used over other ways are not clear from the vague names and class designs (and possibly incomplete details) I provided. However, I really found the solution interesting and felt like sharing it.\"), mdx(\"p\", null, \"You can always share your thoughts on this by @\\u2018ing me on Twitter or LinkedIn (links are available in my author bio) or even this blog\\u2019s \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://github.com/mitesh1612/blog\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"GitHub repo\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;","hero":{"full":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAeRWJKQH/8QAGBAAAgMAAAAAAAAAAAAAAAAAAAERICH/2gAIAQEAAQUCROOn/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Bh//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABoQAAICAwAAAAAAAAAAAAAAAAARECExQVH/2gAIAQEAAT8hNtK6ZDHH/9oADAMBAAIAAwAAABBQ7//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EIR//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGBABAQEBAQAAAAAAAAAAAAAAAQARIVH/2gAIAQEAAT8QQeY8ZwA+AC6ah2FalVv/2Q==","aspectRatio":1.5,"src":"/blog/static/688ac66cebc55f3a61f17cc751030db0/58fe7/hero.jpg","srcSet":"/blog/static/688ac66cebc55f3a61f17cc751030db0/e0f30/hero.jpg 236w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/86afd/hero.jpg 472w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/58fe7/hero.jpg 944w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/02748/hero.jpg 1416w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/5c241/hero.jpg 1888w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/e147c/hero.jpg 5760w","srcWebp":"/blog/static/688ac66cebc55f3a61f17cc751030db0/99fbb/hero.webp","srcSetWebp":"/blog/static/688ac66cebc55f3a61f17cc751030db0/77392/hero.webp 236w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/1f177/hero.webp 472w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/99fbb/hero.webp 944w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/4a492/hero.webp 1416w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/b0b8f/hero.webp 1888w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/b4d70/hero.webp 5760w","sizes":"(max-width: 944px) 100vw, 944px"},"regular":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAeRWJKQH/8QAGBAAAgMAAAAAAAAAAAAAAAAAAAERICH/2gAIAQEAAQUCROOn/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Bh//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABoQAAICAwAAAAAAAAAAAAAAAAARECExQVH/2gAIAQEAAT8hNtK6ZDHH/9oADAMBAAIAAwAAABBQ7//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EIR//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGBABAQEBAQAAAAAAAAAAAAAAAQARIVH/2gAIAQEAAT8QQeY8ZwA+AC6ah2FalVv/2Q==","aspectRatio":1.5,"src":"/blog/static/688ac66cebc55f3a61f17cc751030db0/1dc0b/hero.jpg","srcSet":"/blog/static/688ac66cebc55f3a61f17cc751030db0/3a5ce/hero.jpg 163w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/05730/hero.jpg 327w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/1dc0b/hero.jpg 653w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/f72c7/hero.jpg 980w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/6e4a3/hero.jpg 1306w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/e147c/hero.jpg 5760w","srcWebp":"/blog/static/688ac66cebc55f3a61f17cc751030db0/0acdf/hero.webp","srcSetWebp":"/blog/static/688ac66cebc55f3a61f17cc751030db0/ac59e/hero.webp 163w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/7660b/hero.webp 327w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/0acdf/hero.webp 653w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/75470/hero.webp 980w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/68d47/hero.webp 1306w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/b4d70/hero.webp 5760w","sizes":"(max-width: 653px) 100vw, 653px"},"narrow":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAeRWJKQH/8QAGBAAAgMAAAAAAAAAAAAAAAAAAAERICH/2gAIAQEAAQUCROOn/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Bh//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABoQAAICAwAAAAAAAAAAAAAAAAARECExQVH/2gAIAQEAAT8hNtK6ZDHH/9oADAMBAAIAAwAAABBQ7//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EIR//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGBABAQEBAQAAAAAAAAAAAAAAAQARIVH/2gAIAQEAAT8QQeY8ZwA+AC6ah2FalVv/2Q==","aspectRatio":1.5,"src":"/blog/static/688ac66cebc55f3a61f17cc751030db0/eaa58/hero.jpg","srcSet":"/blog/static/688ac66cebc55f3a61f17cc751030db0/5a3ee/hero.jpg 114w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/41f8f/hero.jpg 229w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/eaa58/hero.jpg 457w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/c309b/hero.jpg 686w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/e3008/hero.jpg 914w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/e147c/hero.jpg 5760w","srcWebp":"/blog/static/688ac66cebc55f3a61f17cc751030db0/15384/hero.webp","srcSetWebp":"/blog/static/688ac66cebc55f3a61f17cc751030db0/31fce/hero.webp 114w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/e3e25/hero.webp 229w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/15384/hero.webp 457w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/0258d/hero.webp 686w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/64ea2/hero.webp 914w,\n/blog/static/688ac66cebc55f3a61f17cc751030db0/b4d70/hero.webp 5760w","sizes":"(max-width: 457px) 100vw, 457px"},"seo":{"src":"/blog/static/688ac66cebc55f3a61f17cc751030db0/0ff54/hero.jpg"}}},"authors":[{"authorsPage":true,"bio":"Hey, I am the writer and the maintainer of this blog.\nRight now I work in Microsoft as a Software Engineer and love to read about Data Science in my free time.\n","id":"a48bda25-fe16-5d41-8d28-669927e22baf","name":"Mitesh Shah","featured":true,"social":[{"url":"https://github.com/mitesh1612"},{"url":"https://linkedin.com/in/mitesh-shah16"}],"slug":"/authors/Mitesh-Shah","avatar":{"small":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAMEBQIG/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAdmnxmp6RQDBGRKB/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAwQREkH/2gAIAQEAAQUCNnK0XbfUYkrjhlt6nAngGh//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAVEQEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAgEBPwEh/8QAHBAAAQQDAQAAAAAAAAAAAAAAAQAQERIhMUFS/9oACAEBAAY/AiTxV9ZDESsrbW7Lf//EABwQAAICAwEBAAAAAAAAAAAAAAABESExUXFBkf/aAAgBAQABPyFSvSTRfE87pHbJk+ag80olt9Ou7YlHJFxS30//2gAMAwEAAgADAAAAEDQI/f/EABcRAQADAAAAAAAAAAAAAAAAAAABEBH/2gAIAQMBAT8QYmv/xAAXEQADAQAAAAAAAAAAAAAAAAAAARAR/9oACAECAQE/EEbX/8QAHRABAQEAAgIDAAAAAAAAAAAAAREAIVExYbHB0f/aAAgBAQABPxBqlCOShqpylpg6esCln0GryrAuEIqoj085r9/9xaIq8kW4QFK+nlPjEOJXl13/2Q==","aspectRatio":0.9975186104218362,"src":"/blog/static/cdf5729ea644380832682af41df572f1/fa1ea/MiteshShah.jpg","srcSet":"/blog/static/cdf5729ea644380832682af41df572f1/afb2b/MiteshShah.jpg 13w,\n/blog/static/cdf5729ea644380832682af41df572f1/7c20e/MiteshShah.jpg 25w,\n/blog/static/cdf5729ea644380832682af41df572f1/fa1ea/MiteshShah.jpg 50w,\n/blog/static/cdf5729ea644380832682af41df572f1/03612/MiteshShah.jpg 75w,\n/blog/static/cdf5729ea644380832682af41df572f1/61cdf/MiteshShah.jpg 100w,\n/blog/static/cdf5729ea644380832682af41df572f1/7a27b/MiteshShah.jpg 2010w","srcWebp":"/blog/static/cdf5729ea644380832682af41df572f1/e7b2c/MiteshShah.webp","srcSetWebp":"/blog/static/cdf5729ea644380832682af41df572f1/58718/MiteshShah.webp 13w,\n/blog/static/cdf5729ea644380832682af41df572f1/74aad/MiteshShah.webp 25w,\n/blog/static/cdf5729ea644380832682af41df572f1/e7b2c/MiteshShah.webp 50w,\n/blog/static/cdf5729ea644380832682af41df572f1/ed320/MiteshShah.webp 75w,\n/blog/static/cdf5729ea644380832682af41df572f1/66016/MiteshShah.webp 100w,\n/blog/static/cdf5729ea644380832682af41df572f1/24292/MiteshShah.webp 2010w","sizes":"(max-width: 50px) 100vw, 50px"},"medium":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAMEBQIG/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAdmnxmp6RQDBGRKB/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAwQREkH/2gAIAQEAAQUCNnK0XbfUYkrjhlt6nAngGh//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAVEQEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAgEBPwEh/8QAHBAAAQQDAQAAAAAAAAAAAAAAAQAQERIhMUFS/9oACAEBAAY/AiTxV9ZDESsrbW7Lf//EABwQAAICAwEBAAAAAAAAAAAAAAABESExUXFBkf/aAAgBAQABPyFSvSTRfE87pHbJk+ag80olt9Ou7YlHJFxS30//2gAMAwEAAgADAAAAEDQI/f/EABcRAQADAAAAAAAAAAAAAAAAAAABEBH/2gAIAQMBAT8QYmv/xAAXEQADAQAAAAAAAAAAAAAAAAAAARAR/9oACAECAQE/EEbX/8QAHRABAQEAAgIDAAAAAAAAAAAAAREAIVExYbHB0f/aAAgBAQABPxBqlCOShqpylpg6esCln0GryrAuEIqoj085r9/9xaIq8kW4QFK+nlPjEOJXl13/2Q==","aspectRatio":0.9975186104218362,"src":"/blog/static/cdf5729ea644380832682af41df572f1/61cdf/MiteshShah.jpg","srcSet":"/blog/static/cdf5729ea644380832682af41df572f1/7c20e/MiteshShah.jpg 25w,\n/blog/static/cdf5729ea644380832682af41df572f1/fa1ea/MiteshShah.jpg 50w,\n/blog/static/cdf5729ea644380832682af41df572f1/61cdf/MiteshShah.jpg 100w,\n/blog/static/cdf5729ea644380832682af41df572f1/59538/MiteshShah.jpg 150w,\n/blog/static/cdf5729ea644380832682af41df572f1/fd013/MiteshShah.jpg 200w,\n/blog/static/cdf5729ea644380832682af41df572f1/7a27b/MiteshShah.jpg 2010w","srcWebp":"/blog/static/cdf5729ea644380832682af41df572f1/66016/MiteshShah.webp","srcSetWebp":"/blog/static/cdf5729ea644380832682af41df572f1/74aad/MiteshShah.webp 25w,\n/blog/static/cdf5729ea644380832682af41df572f1/e7b2c/MiteshShah.webp 50w,\n/blog/static/cdf5729ea644380832682af41df572f1/66016/MiteshShah.webp 100w,\n/blog/static/cdf5729ea644380832682af41df572f1/d9b14/MiteshShah.webp 150w,\n/blog/static/cdf5729ea644380832682af41df572f1/6b183/MiteshShah.webp 200w,\n/blog/static/cdf5729ea644380832682af41df572f1/24292/MiteshShah.webp 2010w","sizes":"(max-width: 100px) 100vw, 100px"},"large":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAMEBQIG/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAdmnxmp6RQDBGRKB/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAwQREkH/2gAIAQEAAQUCNnK0XbfUYkrjhlt6nAngGh//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAVEQEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAgEBPwEh/8QAHBAAAQQDAQAAAAAAAAAAAAAAAQAQERIhMUFS/9oACAEBAAY/AiTxV9ZDESsrbW7Lf//EABwQAAICAwEBAAAAAAAAAAAAAAABESExUXFBkf/aAAgBAQABPyFSvSTRfE87pHbJk+ag80olt9Ou7YlHJFxS30//2gAMAwEAAgADAAAAEDQI/f/EABcRAQADAAAAAAAAAAAAAAAAAAABEBH/2gAIAQMBAT8QYmv/xAAXEQADAQAAAAAAAAAAAAAAAAAAARAR/9oACAECAQE/EEbX/8QAHRABAQEAAgIDAAAAAAAAAAAAAREAIVExYbHB0f/aAAgBAQABPxBqlCOShqpylpg6esCln0GryrAuEIqoj085r9/9xaIq8kW4QFK+nlPjEOJXl13/2Q==","aspectRatio":0.9975186104218362,"src":"/blog/static/cdf5729ea644380832682af41df572f1/ec46e/MiteshShah.jpg","srcSet":"/blog/static/cdf5729ea644380832682af41df572f1/a2637/MiteshShah.jpg 82w,\n/blog/static/cdf5729ea644380832682af41df572f1/15203/MiteshShah.jpg 164w,\n/blog/static/cdf5729ea644380832682af41df572f1/ec46e/MiteshShah.jpg 328w,\n/blog/static/cdf5729ea644380832682af41df572f1/b69a5/MiteshShah.jpg 492w,\n/blog/static/cdf5729ea644380832682af41df572f1/23a36/MiteshShah.jpg 656w,\n/blog/static/cdf5729ea644380832682af41df572f1/7a27b/MiteshShah.jpg 2010w","srcWebp":"/blog/static/cdf5729ea644380832682af41df572f1/5a48e/MiteshShah.webp","srcSetWebp":"/blog/static/cdf5729ea644380832682af41df572f1/2d087/MiteshShah.webp 82w,\n/blog/static/cdf5729ea644380832682af41df572f1/29d87/MiteshShah.webp 164w,\n/blog/static/cdf5729ea644380832682af41df572f1/5a48e/MiteshShah.webp 328w,\n/blog/static/cdf5729ea644380832682af41df572f1/42f2e/MiteshShah.webp 492w,\n/blog/static/cdf5729ea644380832682af41df572f1/dec03/MiteshShah.webp 656w,\n/blog/static/cdf5729ea644380832682af41df572f1/24292/MiteshShah.webp 2010w","sizes":"(max-width: 328px) 100vw, 328px"}}}],"basePath":"/","slug":"/Constructing-a-complex-dictionary-of-base-and-derived-class-using-the-same-code","id":"d525c443-3d53-5eb6-a755-6f6f1805420b","title":"Constructing a complex dictionary of base and derived class using the same code","mailchimp":"","next":[{"id":"b7a2539b-8958-53e7-9d69-e31d4628fa26","slug":"/Welcome-to-this-blog","secret":false,"title":"Welcome to this blog","author":"Mitesh Shah","date":"August 12th, 2020","dateForSEO":"2020-08-12T00:00:00.000Z","timeToRead":1,"excerpt":"A short introduction and welcome to my blog.","subscription":true,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Welcome to this blog\",\n  \"author\": \"Mitesh Shah\",\n  \"date\": \"2020-08-12T00:00:00.000Z\",\n  \"hero\": \"./images/hero.jpg\",\n  \"excerpt\": \"A short introduction and welcome to my blog.\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", {\n    \"id\": \"welcome-to-this-blog\"\n  }, \"Welcome to this blog\"), mdx(\"p\", null, \"Hey everyone, welcome to my blog. I finally took the leap and set up my blog, and after a lot of thinking, I finally decided to create a blog.\"), mdx(\"p\", null, \"Why a blog? Well among a lot of other reasons, like not forgetting what I learn from time to time, and to keep track of my journey as a Software Development Engineer. The other huge reason is that I love to learn new things, research the ones I find interesting, and I plan to document and share my learnings via blog posts, which can be easily found and referred to later as well. I\\u2019ll try to share things I learn about Software Development, my interests in Data Science and all the other random things I encounter. Hopefully, other people will also find these posts helpful, relevant or interesting. You can always share your views on my GitHub repo \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://github.com/mitesh1612/blog\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"here\"), \" (until I figure out adding comment sections to a static GitHub site \\uD83D\\uDE09)\"), mdx(\"p\", null, \"Thanks for visiting this blog!\"), mdx(\"h2\", {\n    \"id\": \"about-me\"\n  }, \"About Me\"), mdx(\"p\", null, \"I\\u2019m Mitesh Shah, and I live in Hyderabad. I started my journey as a Software Engineer at Microsoft (where I currently work). I have a lot of interest in Data Science and Machine Learning and I love reading books or playing some games in my relaxing time.\"), mdx(\"h2\", {\n    \"id\": \"technical-details-for-this-blog\"\n  }, \"Technical Details for this Blog\"), mdx(\"p\", null, \"This blog is possible due to \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.gatsbyjs.org/\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"Gatsby JS\"), \" with the wonderful theme \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/narative/gatsby-theme-novela\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"Novela\"), \" created by the Narative Team. Right now this site is hosted on GitHub pages using a CI from GitHub Actions\"));\n}\n;\nMDXContent.isMDXComponent = true;","hero":{"full":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEAQX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABis47DBJL/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAwQQEyH/2gAIAQEAAQUCpo6gYcI9Vys6vr//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAeEAABAwQDAAAAAAAAAAAAAAABABARAiIxMnGRof/aAAgBAQAGPwInELfxrZHBW1Xbf//EABsQAAIDAQEBAAAAAAAAAAAAAAABESExYUHx/9oACAEBAAE/IbqVXjYyYUZ7LWabiXgfbjanD//aAAwDAQACAAMAAAAQB+//xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQMBAT8Q1X//xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQIBAT8QxH//xAAfEAEAAgIABwAAAAAAAAAAAAABABEhMUFRYXGBkbH/2gAIAQEAAT8Q3EYaS3fAekrjLDH0uYNyEWrmvMaQba23qPeJKTu82f/Z","aspectRatio":1.5011258443832876,"src":"/blog/static/089485aa0376348ea253235c372675de/58fe7/hero.jpg","srcSet":"/blog/static/089485aa0376348ea253235c372675de/e0f30/hero.jpg 236w,\n/blog/static/089485aa0376348ea253235c372675de/86afd/hero.jpg 472w,\n/blog/static/089485aa0376348ea253235c372675de/58fe7/hero.jpg 944w,\n/blog/static/089485aa0376348ea253235c372675de/02748/hero.jpg 1416w,\n/blog/static/089485aa0376348ea253235c372675de/5c241/hero.jpg 1888w,\n/blog/static/089485aa0376348ea253235c372675de/39dd0/hero.jpg 6000w","srcWebp":"/blog/static/089485aa0376348ea253235c372675de/99fbb/hero.webp","srcSetWebp":"/blog/static/089485aa0376348ea253235c372675de/77392/hero.webp 236w,\n/blog/static/089485aa0376348ea253235c372675de/1f177/hero.webp 472w,\n/blog/static/089485aa0376348ea253235c372675de/99fbb/hero.webp 944w,\n/blog/static/089485aa0376348ea253235c372675de/4a492/hero.webp 1416w,\n/blog/static/089485aa0376348ea253235c372675de/b0b8f/hero.webp 1888w,\n/blog/static/089485aa0376348ea253235c372675de/e26e3/hero.webp 6000w","sizes":"(max-width: 944px) 100vw, 944px"},"regular":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEAQX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABis47DBJL/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAwQQEyH/2gAIAQEAAQUCpo6gYcI9Vys6vr//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAeEAABAwQDAAAAAAAAAAAAAAABABARAiIxMnGRof/aAAgBAQAGPwInELfxrZHBW1Xbf//EABsQAAIDAQEBAAAAAAAAAAAAAAABESExYUHx/9oACAEBAAE/IbqVXjYyYUZ7LWabiXgfbjanD//aAAwDAQACAAMAAAAQB+//xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQMBAT8Q1X//xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQIBAT8QxH//xAAfEAEAAgIABwAAAAAAAAAAAAABABEhMUFRYXGBkbH/2gAIAQEAAT8Q3EYaS3fAekrjLDH0uYNyEWrmvMaQba23qPeJKTu82f/Z","aspectRatio":1.5011258443832876,"src":"/blog/static/089485aa0376348ea253235c372675de/1dc0b/hero.jpg","srcSet":"/blog/static/089485aa0376348ea253235c372675de/3a5ce/hero.jpg 163w,\n/blog/static/089485aa0376348ea253235c372675de/05730/hero.jpg 327w,\n/blog/static/089485aa0376348ea253235c372675de/1dc0b/hero.jpg 653w,\n/blog/static/089485aa0376348ea253235c372675de/f72c7/hero.jpg 980w,\n/blog/static/089485aa0376348ea253235c372675de/6e4a3/hero.jpg 1306w,\n/blog/static/089485aa0376348ea253235c372675de/39dd0/hero.jpg 6000w","srcWebp":"/blog/static/089485aa0376348ea253235c372675de/0acdf/hero.webp","srcSetWebp":"/blog/static/089485aa0376348ea253235c372675de/ac59e/hero.webp 163w,\n/blog/static/089485aa0376348ea253235c372675de/7660b/hero.webp 327w,\n/blog/static/089485aa0376348ea253235c372675de/0acdf/hero.webp 653w,\n/blog/static/089485aa0376348ea253235c372675de/75470/hero.webp 980w,\n/blog/static/089485aa0376348ea253235c372675de/68d47/hero.webp 1306w,\n/blog/static/089485aa0376348ea253235c372675de/e26e3/hero.webp 6000w","sizes":"(max-width: 653px) 100vw, 653px"},"narrow":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEAQX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABis47DBJL/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAwQQEyH/2gAIAQEAAQUCpo6gYcI9Vys6vr//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAeEAABAwQDAAAAAAAAAAAAAAABABARAiIxMnGRof/aAAgBAQAGPwInELfxrZHBW1Xbf//EABsQAAIDAQEBAAAAAAAAAAAAAAABESExYUHx/9oACAEBAAE/IbqVXjYyYUZ7LWabiXgfbjanD//aAAwDAQACAAMAAAAQB+//xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQMBAT8Q1X//xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQIBAT8QxH//xAAfEAEAAgIABwAAAAAAAAAAAAABABEhMUFRYXGBkbH/2gAIAQEAAT8Q3EYaS3fAekrjLDH0uYNyEWrmvMaQba23qPeJKTu82f/Z","aspectRatio":1.5011258443832876,"src":"/blog/static/089485aa0376348ea253235c372675de/eaa58/hero.jpg","srcSet":"/blog/static/089485aa0376348ea253235c372675de/5a3ee/hero.jpg 114w,\n/blog/static/089485aa0376348ea253235c372675de/41f8f/hero.jpg 229w,\n/blog/static/089485aa0376348ea253235c372675de/eaa58/hero.jpg 457w,\n/blog/static/089485aa0376348ea253235c372675de/c309b/hero.jpg 686w,\n/blog/static/089485aa0376348ea253235c372675de/e3008/hero.jpg 914w,\n/blog/static/089485aa0376348ea253235c372675de/39dd0/hero.jpg 6000w","srcWebp":"/blog/static/089485aa0376348ea253235c372675de/15384/hero.webp","srcSetWebp":"/blog/static/089485aa0376348ea253235c372675de/31fce/hero.webp 114w,\n/blog/static/089485aa0376348ea253235c372675de/e3e25/hero.webp 229w,\n/blog/static/089485aa0376348ea253235c372675de/15384/hero.webp 457w,\n/blog/static/089485aa0376348ea253235c372675de/0258d/hero.webp 686w,\n/blog/static/089485aa0376348ea253235c372675de/64ea2/hero.webp 914w,\n/blog/static/089485aa0376348ea253235c372675de/e26e3/hero.webp 6000w","sizes":"(max-width: 457px) 100vw, 457px"},"seo":{"src":"/blog/static/089485aa0376348ea253235c372675de/0ff54/hero.jpg"}}},{"id":"ed31c57c-d2e6-514d-8338-7b586115eba6","slug":"/The-Naivete-of-Naive-Bayes","secret":false,"title":"The Naivete of Naive Bayes","author":"Mitesh Shah","date":"August 30th, 2020","dateForSEO":"2020-08-30T00:00:00.000Z","timeToRead":10,"excerpt":"A \"from scratch\" implementation of Naive Bayes algorithm to find a whether a message is spam or not and a kick off to the series \"Machine Learning, with the Maths\"","subscription":true,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"The Naivete of Naive Bayes\",\n  \"author\": \"Mitesh Shah\",\n  \"date\": \"2020-08-30T00:00:00.000Z\",\n  \"hero\": \"./images/hero.png\",\n  \"excerpt\": \"A \\\"from scratch\\\" implementation of Naive Bayes algorithm to find a whether a message is spam or not and a kick off to the series \\\"Machine Learning, with the Maths\\\"\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"So I finally figured out how to render LaTeX equations on my blog, and thus I can use my truly \\u201Cuseful\\u201D LaTex knowledge to start a new series on something that truly interests me. Machine Learning and how it works using the relative math in a simpler (and hopefully fun) language, to not scare away people who don\\u2019t prefer maths. Welcome to my series \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Machine Learning, with the Maths\"), \"! (It sounds way cooler in my head!)\"), mdx(\"p\", null, \"The point of this series is not to be a substitute for the plethora of tutorials already available on the topic of Machine Learning. I will try to explain the basic concepts behind each machine learning algorithm, and try to implement it from scratch using Python and NumPy. Maybe you can and hopefully will find better resources, but I hope this can be a good start for you. Plus, where else can I use my superbly huge and comically large Latex equations. Let\\u2019s begin, this probably very long post.\"), mdx(\"p\", null, \"I am planning to write an introductory post on Bayes theorem anyways, so I am gonna skip the gory details here and link it in this post when I do end up writing it. Here\\u2019s the short intro to Bayes theorem.\"), mdx(\"p\", null, \"There are a lot of ways to define what Bayes theorem represents. It can be thought of way to \\u201Creverse\\u201D conditional probabilities. The interpretation we will be going through is that it can be used to find the probability of an event occurring, given the probability of another event that has already occurred. We can use (fun?) letters to denote some events, but hey, this is a Machine Learning post, so lets talk like that. Say you have a hypothesis (or an assumption) and you want to find the probability of that assumption, given the data. That is actually what Bayes theorem gives! Don\\u2019t believe me?. Let\\u2019s look at the equations\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"773px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"36.99870633893919%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAnElEQVQY041RywrDIBD0/78rZ4+5iYoe1EgeIjGRNu2gIU0ppJmDrLMzs4uS1z1s2/ZLknO7Ks461M+CWjwKDgG5HiWlpJRO09S2rTEGZ9M0uFbBbkaqUgrSGKPWehxHMOu6guGce++HYej73jmHCNQ1+mOGhzEWQrDWdl2XUgKfc4YOHiEEWsuyxIIv8/XyGI6F53n+82AH7nzBG501l9eaTgmUAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/ee58a58b837eb9307fc5837da49a5cba/7f6ca/bayesequation.webp 773w\"],\n    \"sizes\": \"(max-width: 773px) 100vw, 773px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/ee58a58b837eb9307fc5837da49a5cba/ecf91/bayesequation.png 773w\"],\n    \"sizes\": \"(max-width: 773px) 100vw, 773px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/blog/static/ee58a58b837eb9307fc5837da49a5cba/ecf91/bayesequation.png\",\n    \"alt\": \"Bayes Theorem Equation\",\n    \"title\": \"Bayes Theorem Equation\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, \"This says that the gives the probability of event E occuring, given some event F occurs. Say event \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"E\"), \" represents our hypothesis and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"F\"), \" represents the probability of obsering the data we observe. Then P(E|F) basically represents how much the data supports our assumption. Hence many times, Bayes theorem is also written like this\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1436px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"17.548746518105848%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAf0lEQVQI132OywoDIQxF/f8vFFz4qDBiVapTtIp2eiezbOlZyCUmJ2HHL0opKaVaa2vtQeSce+/OuTsRQlhrMaXUjYgxeu+ttWhFFkIYY7Zt45xLKZExjzZkrTUs2MGexL7v2PMixhiwXiegDjsUCG8Cxes9h4+/wNKJOef37wcVuOUnSxQ8LwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/45838f1e722ec5ecbed2c8caa25463cd/d7181/bayes2.webp 1436w\"],\n    \"sizes\": \"(max-width: 1436px) 100vw, 1436px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/45838f1e722ec5ecbed2c8caa25463cd/8f501/bayes2.png 1436w\"],\n    \"sizes\": \"(max-width: 1436px) 100vw, 1436px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/blog/static/45838f1e722ec5ecbed2c8caa25463cd/8f501/bayes2.png\",\n    \"alt\": \"Bayes Theorem Equation again\",\n    \"title\": \"Bayes Theorem Equation again\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, \"The term P(Hypothesis) is also called \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"prior\"), \" or \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"prior beliefs\"), \". Why prior? It is the degree of the conviction that the hypothesis is true \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"before we observe\"), \" the actual data. Remember, prior is the sometimes the trickiest terms to determine (\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"#the-horrors-of-prior\"\n  }), \"as mentioned later here\"), \"). The term P(Hypothesis|Data) is called the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"posterior\"), \" probability, which represents \\u201Cthe possibility of the hypothesis, given the data\\u201D. Posterior is usually build after seeing the data. The term P(Data|Hypothesis) is a fun one. It represents the probability of having obtained the data, given the hypothesis and is called the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"likelihood\"), \" term. In that way, P(Data) is the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Evidence\"), \" we have, or the data we have.\"), mdx(\"p\", null, \"The evidence term can be broken as P(F) = P(F|E)P(E) + P(F|E\\u2019)P(E\\u2019) as well, which might come in handy later.\"), mdx(\"h2\", {\n    \"id\": \"how-bayes-theorem-is-relevant-to-machine-learning\"\n  }, \"How Bayes Theorem is relevant to Machine Learning?\"), mdx(\"p\", null, \"What Bayes theorem gives us is a framework to update our beliefs using evidence. Say you have a prior belief that some event occurs. Then you receive some evidence. You weigh your prior using the likelihood of that evidence happening and get a new belief, the posterior! Now when you get some more new evidence, you replace your prior belief with the posterior found about the event, and get a new posterior belief. And hey if you are not a probability nerd, let me explain this to you in a simpler way. Say you are a man who have lived his whole life inside a cave, and never got out. Now once you get out and see the sun rising on the east, what do you believe? Does it always happen or is this a one off? You assign some \\u201Cprior\\u201D probability of the sun rising in the east. The next day, the sun rises in east again and you update your belief using this evidence. Hmm, sun might rise on east on Mondays and Tuesdays and again update your belief (posterior). The more evidence you gather, the more you are sure about an event, and frankly that\\u2019s the crux of Machine Learning as well. We use data, or evidence, to update our beliefs about something.\"), mdx(\"p\", null, \"Now with that out of the way, let\\u2019s turn to the example and actually implement this.\"), mdx(\"h2\", {\n    \"id\": \"spam-me-not\"\n  }, \"Spam me not!\"), mdx(\"p\", null, \"The most common use of Naive Bayes, is for spam filters. Let\\u2019s look into how we can implement a spam filter using Naive Bayes from scratch. \"), mdx(\"p\", null, \"Sometime ago, there was a scam on twitter where accounts of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://economictimes.indiatimes.com/magazines/panache/twitter-accounts-of-bill-gates-jeff-bezos-elon-musk-hacked-in-bitcoin-scam/articleshow/76991797.cms\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"famous people like Elon Musk, Jeff Bezos etc. were hacked for \\u201Cbitcoin\\u201D scams\"), \", and let\\u2019s try to build a spam filter to help the poor souls who actually sent bitcoins to this scam. Let \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"S\"), \" be the event that \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"the message is spam\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"B\"), \" be the event that \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"the message contains the word \\u2018bitcoin\\u2019\"), \". Baye\\u2019s theorem tells us that the conditional probability that the message is spam, given it contains the word bitcoin is:\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"747px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"20.348058902275767%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAjUlEQVQI13WO2QqDMBRE/f8fTMxagsEgiIY0xGbRTtMXKfQ8DJe5c5fh+k8p5dkJIcQYoXDugaG15pxb19VaiwTaOWcofO+9MebRmedZa73ve601d87z/Axv2wZ3WZbjODCPKCGEUiql5JxP04Qt4zgKIZRSUMYYCoSHn1exD2dTSuihgH6PvDr5Bq6+ATzn5C41pwnvAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/1e63d5812db19be7c4108fd95db1b61f/e93c1/spameqn.webp 747w\"],\n    \"sizes\": \"(max-width: 747px) 100vw, 747px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/1e63d5812db19be7c4108fd95db1b61f/f3b3a/spameqn.png 747w\"],\n    \"sizes\": \"(max-width: 747px) 100vw, 747px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/blog/static/1e63d5812db19be7c4108fd95db1b61f/f3b3a/spameqn.png\",\n    \"alt\": \"Bayes Theorem on Spam Probability\",\n    \"title\": \"Bayes Theorem on Spam Probability\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, \"The numerator is the probability that a message is spam \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"and\"), \" contains \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitcoin\"), \", while the denominator is just the probability that a message contains \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitcoin\"), \". How? P(B|S)P(S) = P(B,S) using the definition of conditional probablity (on which I did write a \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://mitesh1612.github.io/blog/Conditional-Probability-and-Families\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"fun post you can read here\"), \") and the denominator is essentially P(B). In this sense, we can think of this calculation simply representing the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"proportion\"), \" of \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitcoin\"), \" messages are spam.\"), mdx(\"p\", null, \"Say we have a large number of messages that we know are \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"spam\"), \" and a large collection of messages that we know are \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ham\"), \" (the word used for not spam commonly). Using that we can easily estimate P(B|S) and P(B|S\\u2019). Let\\u2019s make an assumption that it is equally likely that a message is spam or ham. Then P(S) = P(S\\u2019) = 0.5. Taking out the common term in the above equation, we get\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"567px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"26.984126984126984%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAl0lEQVQY04WO2QqDMBBF/f//i0EJiUTwRTEQYxaCtqcLhdaHXgjcZe5Mmts/nOf5Qz5oeMdxXIOXk1IyxiilxnG01iK/yrVWMibIhBDLsoQQ9n13zm3bNs/zNE2klIdhQGKu61pKeZQ5G2P03tOhAMdltOs6KWXf91prTArwtm3xucGK97evYDHH2cg/IfUJTBxkzhnJ2B0Ash5OIxeJGQAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/4a70ed4d864ccb4cee84c31aa316cad6/fead4/spameqn2.webp 567w\"],\n    \"sizes\": \"(max-width: 567px) 100vw, 567px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/4a70ed4d864ccb4cee84c31aa316cad6/529a1/spameqn2.png 567w\"],\n    \"sizes\": \"(max-width: 567px) 100vw, 567px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/blog/static/4a70ed4d864ccb4cee84c31aa316cad6/529a1/spameqn2.png\",\n    \"alt\": \"Spam Equation after assumptions\",\n    \"title\": \"Spam Equation after assumptions\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, \"Now say we find out that 50% of the spam messages contain the word bitcoin but only 1% of non spam messages do, then the probablity that any given \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitcoin\"), \"-containing message is spam is:\"), mdx(\"p\", null, \"0.5/(0.5 + 0.01) = 98%\"), mdx(\"h3\", {\n    \"id\": \"making-the-spam-filter-more-sophisticated\"\n  }, \"Making the Spam Filter more Sophisticated\"), mdx(\"p\", null, \"Let\\u2019s bring in equations now (this aint called Machine Learning with Maths for no reason). Imagine we have a vocabulary of many words w1, w2, \\u2026 ,wn and we say event Xi means the message contains the word wi. Also, since we are imagining so much, imagine that we have some undisclosed process to get an estimate of P(Xi|S) and P(Xi|S\\u2019), or basically the probability that a spam/not spam message contains the ith word.\"), mdx(\"h3\", {\n    \"id\": \"why-is-this-bayes-naive\"\n  }, \"Why is this Bayes Naive?\"), mdx(\"p\", null, \"The key to Naive Bayes is making the (big) assumption that the presences (or absences) of each word are independent of one another, conditional on a message being spam or not. Intuitively, this assumption means that knowing whether a certain spam message contains the word \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitcoin\"), \" gives you no information about whether that same message contains the word \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"rolex\"), \". In terms of ML terminologies, it makes the assumption that features of a measurement are independent of each other.\"), mdx(\"p\", null, \"In math terms, this assumption means that:\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1174px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"8.517887563884157%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAIAAADXZGvcAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAATUlEQVQI1yWNUQpAIQgEu/9ZJTB72pOIhvTH3XEXW2autfbeEYHAmtmcEysi/xtVdfdzDoHeO5oYmcbiDAVRQEOxiDFGlYvwgPD3puAFlixzwIHYcpsAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/90f85092ec8d71cacbeab2c5d412b229/059d3/naive.webp 1174w\"],\n    \"sizes\": \"(max-width: 1174px) 100vw, 1174px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/90f85092ec8d71cacbeab2c5d412b229/2e7a4/naive.png 1174w\"],\n    \"sizes\": \"(max-width: 1174px) 100vw, 1174px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/blog/static/90f85092ec8d71cacbeab2c5d412b229/2e7a4/naive.png\",\n    \"alt\": \"Naive Assumption of Naive Bayes\",\n    \"title\": \"Naive Assumption of Naive Bayes\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, \"Now I am not going to lie, this is an extreme assumption, and the reason why it is called Naive Bayes. Say our vocabulary contains only the words \\u201Cbitcoin\\u201D and \\u201Cgold\\u201D and that half the messages that are spam are for \\u201Cearn bitcoin\\u201D and the other half messages that are spam are for \\u201C26kt gold\\u201D. Thus P(Bitcoin|Spam) = 0.5 and P(Gold|Scam) = 0.5 as well. The probability that a message is spam which contains both \\u201Cbitcoin\\u201D and \\u201Cgold\\u201D is P(Bitcoin, Gold|Spam) = P(Bitcoin|Spam) * P(Gold|Spam) = 0.5 x 0.5 = 0.25. This happens since we assumed away the knowledge that \\u201Cbitcoin\\u201D and \\u201Cgold\\u201D never occur together.\"), mdx(\"p\", null, \"The fun part is that, despite the unrealisticness of this assumption, this model often performs well and has historically been used in actual spam filters.\"), mdx(\"p\", null, \"Using the same equation that we used for the bitcoin only spam filter, we can calculate the probability of a message being spam using the following equation:\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"875px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"17.142857142857142%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAIAAAAcOLh5AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAcElEQVQI132NyQ4DIQxD5/9/EgFi2ARiX4Vat3ProT5ET46dXK+/KqXUWs85c07wz/ZKKd33rZRCKISARO/dOQcfTCklhFhrGWOAnDNM7/0Y41PG1bXW3hvwzNYa5/zJGWOEEDgUY9Rap6+klPiE8hsiDKwhcyP1IgAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/0aec3dc42e335d873d7eaaa21dd0b21d/e1e78/sophisticatedspam.webp 875w\"],\n    \"sizes\": \"(max-width: 875px) 100vw, 875px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/blog/static/0aec3dc42e335d873d7eaaa21dd0b21d/c701c/sophisticatedspam.png 875w\"],\n    \"sizes\": \"(max-width: 875px) 100vw, 875px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/blog/static/0aec3dc42e335d873d7eaaa21dd0b21d/c701c/sophisticatedspam.png\",\n    \"alt\": \"Bayes Theorem on Sophisticated Spam Filter\",\n    \"title\": \"Bayes Theorem on Sophisticated Spam Filter\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, \"The Naive Bayes assumption allows us to compute each of the probabilities on the right simply by multiplying together the individual probability estimates for each vocabulary word and hence simplifies our calculation.\"), mdx(\"h3\", {\n    \"id\": \"a-practical-consideration\"\n  }, \"A practical consideration\"), mdx(\"p\", null, \"In order to prevent \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://en.wikipedia.org/wiki/Arithmetic_underflow\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"underflow\"), \", where in computers don\\u2019t do well with floating-point numbers that are too close to 0, we try to avoid multiplying probability values. Instead of that, we can use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"log\"), \" to multiply probabilities using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"log(ab) = log(a) + log(b)\"), \" and then do an \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"exp(logx) = x\"), \" to get back the actual probability. This doesn\\u2019t change any of the equations or assumptions, it is just a small practical trick to avoid getting weird answers.\"), mdx(\"h3\", {\n    \"id\": \"training\"\n  }, \"Training?\"), mdx(\"p\", null, \"Now the only problem is estimating P(Xi|S) and P(Xi|S\\u2019), the probabilities that a spam message (or nonspam message) contains the word wi. If we have a fair number of \\u201Ctraining\\u201D messages labeled as spam and not spam, an obvious first try is to estimate P(Xi|S) simply as the fraction of spam messages containing the word wi.\"), mdx(\"h4\", {\n    \"id\": \"being-smooth\"\n  }, \"Being Smooth\"), mdx(\"p\", null, \"While this calculation seems reasonable, it has a huge problem. Say, in our training messages, the word \\u201Cdata\\u201D only occurs in nonspam messages. Then we\\u2019d estimate P(data|S)=0. The result is that our Naive Bayes classifier would always assign spam probability 0 to any message containing the word \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"data\"), \", even a message like \\u201Cdata on free bitcoin and 26 kt gold free.\\u201D To avoid this, we usually use some kind of \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"smoothing\"), \". One of the simplest ways is to choose a pseudo count \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"k\"), \" (basically assuming that there are atleast \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"k\"), \" spam/ham messages containing the given word i). This gives us the following equation for estimating the probability of seeing the ith word in a spam or ham message as follows:\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://render.githubusercontent.com/render/math?math=P(X_i%7CS)%20%3D%20%5Cfrac%7B(k%20%2B%20%5C%23%20of%20spams%20containing%20w_i)%7D%7B(2k%20%2B%20%5C%23%20of%20spams)%7D%0D\",\n    \"alt\": \"smoothed equation\"\n  }))), mdx(\"p\", null, \"We can do similarly for P(Xi|S\\u2019) where in we assume we also saw k additional nonspams containing the word and k additional nonspams not containing the word.\"), mdx(\"p\", null, \"For example, if data occurs in 0/98 spam messages, and if k is 1, we estimate P(data|S) as 1/100 = 0.01, which allows our classifier to still assign some nonzero spam probability to messages that contain the word \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"data\"), \".\"), mdx(\"h3\", {\n    \"id\": \"code-implementation\"\n  }, \"Code Implementation\"), mdx(\"p\", null, \"Now that we have all the pieces to build our classifier, the only thing to do is to actually build our classifier. This post contains code snippets but you can find the code on my GitHub repo \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/mitesh1612/Machine-Learning-From-Scratch/blob/master/NaiveBayes/NaiveBayes.ipynb\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"here\")), mdx(\"p\", null, \"Since we are planning to deal with text data with this classifier, we will be needing to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"tokenize\"), \" our text to words/tokens. We assume we have a simple function \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"tokenize()\"), \" that returns all the tokens in a sentence. (A simple implementation for this would be to convert all text to lower case and then use regular expressions to remove special characters like apostrophes). We can obviously have complex tokenizing pipelines and more text pre-processings, but we will skip that for now.\"), mdx(\"p\", null, \"Our training data consists of the message and a boolean \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"is_spam\"), \" indicating whether the message is spam?. We implement our classifier as a class to use it in a better way. The constructor only takes the parameter \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"k\"), \". We also initialize a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"set\"), \" to contain unique tokens, dictionaries  which are counters to track how often each token is seen in spam messages and ham messages, and the counts of how many spam and ham messages it was trained on.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"class NaiveBayesClassifier:\\n    def __init__(self, k = 0.5):\\n        self.k = k\\n\\n        self.tokens = set()\\n        self.token_spam_counts = defaultdict(int)\\n        self.token_ham_counts = defaultdict(int)\\n        self.spam_messages = self.ham_messages = 0\\n\")), mdx(\"p\", null, \"Now to implement the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"train\"), \" function for it. According to the message type, we first increment the counts of spam or ham messages. Then we tokenize the message and then increment the spam/ham counts for each token.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"def train(self, messages):\\n    for message in messages:\\n        if message.is_spam:\\n            self.spam_messages += 1\\n        else:\\n            self.ham_messages += 1\\n\\n        # Increment word counts\\n        for token in tokenize(message.text):\\n            self.tokens.add(token)\\n            if message.is_spam:\\n                self.token_spam_counts[token] += 1\\n            else:\\n                self.token_ham_counts[token] += 1\\n\")), mdx(\"p\", null, \"Ultimately we\\u2019ll want to predict P(spam | token). As we saw earlier, to apply Bayes\\u2019s theorem we need to know P(token | spam) and P(token | ham) for each token in the vocabulary. So we\\u2019ll create a helper function to compute those. (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"_probabilities\"), \")\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"def _probabilities(self, token):\\n    \\\"\\\"\\\"\\n    Returns P(token|spam) and P(token|ham)\\n    \\\"\\\"\\\"\\n    spam = self.token_spam_counts[token]\\n    ham = self.token_ham_counts[token]\\n\\n    p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\\n    p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\\n\\n    return p_token_spam, p_token_ham\\n\")), mdx(\"p\", null, \"Finally we can write a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"predict\"), \" method, and we will use the method of summing logs (\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"#a-practical-consideration\"\n  }), \"as mentioned in here\"), \"). This takes a message and tokenizes it. Then using the helper function it finds the probabilities of each token in the vocabulary. Then adds/multiplies the respective probability of seeing/not seeing the token in te message and then returns the probability of the given message being spam or ham.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"def predict(self, text):\\n    text_tokens = tokenize(text)\\n    log_prob_if_spam = log_prob_if_ham = 0.0\\n\\n    # Iterate through each word in vocabulary\\n    for token in self.tokens:\\n        prob_if_spam, prob_if_ham = self._probabilities(token)\\n\\n        # If token appears in message\\n        # add the log probability of seeing it\\n        if token in text_tokens:\\n            log_prob_if_spam += math.log(prob_if_spam)\\n            log_prob_if_ham += math.log(prob_if_ham)\\n        # Otherwise add the log probability\\n        # of not seeing it which is\\n        # log(1-probability of seeing it)\\n        else:\\n            log_prob_if_spam += math.log(1-prob_if_spam)\\n            log_prob_if_ham += math.log(1-prob_if_ham)\\n    prob_if_spam = math.exp(log_prob_if_spam)\\n    prob_if_ham = math.exp(log_prob_if_ham)\\n\")), mdx(\"h3\", {\n    \"id\": \"inspecting-the-model\"\n  }, \"Inspecting the Model\"), mdx(\"p\", null, \"We can even have a helper function that \\u201Cinspect\\u201D the model\\u2019s innards see which words are indicative of spam/not spam.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"def p_spam_given_token(token, model):\\n    prob_if_spam, prob_if_ham = model._probabilities(token)\\n\\n    return prob_if_spam/(prob_if_spam + prob_if_ham)\\nwords = sorted(model.tokens, key=lambda t: p_spam_given_token(t,model))\\nprint(\\\"Spammiest Words: \\\", words[-10:])\\nprint(\\\"Hammiest Words: \\\", words[:10])\\n\")), mdx(\"h4\", {\n    \"id\": \"trying-out-the-model-on-a-dataset\"\n  }, \"Trying out the model on a dataset\"), mdx(\"p\", null, \"We will run this model on the UCI ML SMS Spam Dataset \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"which can be found here\"), \". For the detailed code, you can visit this \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/mitesh1612/Machine-Learning-From-Scratch/blob/master/NaiveBayes/NaiveBayes.ipynb\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"notebook in my GitHub repo\")), mdx(\"p\", null, \"The model returns \\u201Cclaim\\u201D \\u201Cprize\\u201D as words indicating the message is spam which is a good sign of this performing okay.\"), mdx(\"h4\", {\n    \"id\": \"possible-improvements\"\n  }, \"Possible Improvements\"), mdx(\"p\", null, \"How could we get better performance? One obvious way would be to get more data to train on. There are a number of ways to improve the model as well. Here are some possibilities that you might try:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Our classifier takes into account every word that appears in the training set, even words that appear only once. Modify the classifier to accept an optional min_count threshold and ignore tokens that don\\u2019t appear at least that many times.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The tokenizer has no notion of similar words (e.g., cheap and cheapest). Modify the classifier to take an optional stemmer function that converts words to equivalence classes of words.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Although our features are all of the form \\u201Cmessage contains word wi,\\u201D there\\u2019s no reason why this has to be the case. In our implementation, we could add extra features like \\u201Cmessage contains a number\\u201D by creating phony tokens like contains:number and modifying the tokenizer to emit them when appropriate.\")), mdx(\"h2\", {\n    \"id\": \"the-horrors-of-prior\"\n  }, \"The horrors of prior\"), mdx(\"p\", null, \"After all that code, there is one small topic I would like to touch on, which is on estimating priors.\"), mdx(\"p\", null, \"Prior is one of the trickiest terms to determine in the Bayes equation. As explained really nicely in \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://youtu.be/R13BD8qKeTg\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"this video by Veritasium\"), \", Bayes theorem tells us how to update our beliefs in light of new evidence. It cant tell us how to set our prior beliefs. So it is possible for someone to have a different prior belief than other, because they are subjective. Some people might be more certain about a prior belief that other people. That\\u2019s how bias can creep in. And we definitely need a world, and a model, with lesser bias.\"), mdx(\"p\", null, \"Mathematically, instead of \\u201Cchoosing\\u201D a prior, we assume the prior probability to follow a prior model and we try to estimate these model parameters (for example assuming the prior distribution follows Gaussian distribution and finding its parameters)\"), mdx(\"h2\", {\n    \"id\": \"for-further-exploration\"\n  }, \"For further exploration\"), mdx(\"p\", null, \"You can visit \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://aihubprojects.com/naive-bayes-algorithm-from-scratch/\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"this blog\"), \" for another \\u201Cfrom scratch\\u201D implementation of Naive Bayes or \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://chrisalbon.com/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"this blog\"), \" as well .\"), mdx(\"p\", null, \"The idea and much of the code was from the book \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.amazon.in/Data-Science-Scratch-Joel-Grus/dp/149190142X\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"\\u201CData Science from Scratch\\u201D\"), \" which is truly an amazing read for someone who wants to implement stuff from scratch.\"), mdx(\"p\", null, \"If you stuck with me till this long, it seems you enjoyed this post. I hope to keep updating this new \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Machine Learning, with the Maths\"), \" series so keep an eye on this blog. You can always @ me at my socials or the GitHub repo for this blog. Thanks for reading. \\uD83D\\uDE0A\"));\n}\n;\nMDXContent.isMDXComponent = true;","hero":{"full":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA5ElEQVQoz4VSCY7DIAzM/z9ZqaumIkBSQjl9pA7Z7bGNWstCI5jxMaJb3oKZkRAZgYCYVkxUsALhP2b3Lg41ntxZzfowHn8u/Rim0+V8sEd9tVvp+7kj3t4ktrYbkOR27ZybpklrDQD74p1yTzjGKMpPnalWKoUBKCXBK8h5AbiGkFJ67MzCi5EbWxibshpThwFDqFpXayVL3xets/eM+CcWas55GIJS6Fwdx7Vna8WtRFFKij5PtTC/uC07uHm+2/iYvk0rfu1u9yuWZ7FBlvHeG2Nsi68udi8mkXwIlGGhxVfxDVKCTSTID9dwAAAAAElFTkSuQmCC","aspectRatio":2.033966033966034,"src":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/a1946/hero.png","srcSet":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/5b37e/hero.png 236w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/49058/hero.png 472w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/a1946/hero.png 944w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/030f1/hero.png 1416w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/75927/hero.png 1888w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/f5a68/hero.png 2036w","srcWebp":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/99fbb/hero.webp","srcSetWebp":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/77392/hero.webp 236w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/1f177/hero.webp 472w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/99fbb/hero.webp 944w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/4a492/hero.webp 1416w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/b0b8f/hero.webp 1888w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/903d5/hero.webp 2036w","sizes":"(max-width: 944px) 100vw, 944px"},"regular":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA5ElEQVQoz4VSCY7DIAzM/z9ZqaumIkBSQjl9pA7Z7bGNWstCI5jxMaJb3oKZkRAZgYCYVkxUsALhP2b3Lg41ntxZzfowHn8u/Rim0+V8sEd9tVvp+7kj3t4ktrYbkOR27ZybpklrDQD74p1yTzjGKMpPnalWKoUBKCXBK8h5AbiGkFJ67MzCi5EbWxibshpThwFDqFpXayVL3xets/eM+CcWas55GIJS6Fwdx7Vna8WtRFFKij5PtTC/uC07uHm+2/iYvk0rfu1u9yuWZ7FBlvHeG2Nsi68udi8mkXwIlGGhxVfxDVKCTSTID9dwAAAAAElFTkSuQmCC","aspectRatio":2.033966033966034,"src":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/3ddd4/hero.png","srcSet":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/078a8/hero.png 163w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/e56da/hero.png 327w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/3ddd4/hero.png 653w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/c5cc7/hero.png 980w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/eebd2/hero.png 1306w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/f5a68/hero.png 2036w","srcWebp":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/0acdf/hero.webp","srcSetWebp":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/ac59e/hero.webp 163w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/7660b/hero.webp 327w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/0acdf/hero.webp 653w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/75470/hero.webp 980w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/68d47/hero.webp 1306w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/903d5/hero.webp 2036w","sizes":"(max-width: 653px) 100vw, 653px"},"narrow":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA5ElEQVQoz4VSCY7DIAzM/z9ZqaumIkBSQjl9pA7Z7bGNWstCI5jxMaJb3oKZkRAZgYCYVkxUsALhP2b3Lg41ntxZzfowHn8u/Rim0+V8sEd9tVvp+7kj3t4ktrYbkOR27ZybpklrDQD74p1yTzjGKMpPnalWKoUBKCXBK8h5AbiGkFJ67MzCi5EbWxibshpThwFDqFpXayVL3xets/eM+CcWas55GIJS6Fwdx7Vna8WtRFFKij5PtTC/uC07uHm+2/iYvk0rfu1u9yuWZ7FBlvHeG2Nsi68udi8mkXwIlGGhxVfxDVKCTSTID9dwAAAAAElFTkSuQmCC","aspectRatio":2.033966033966034,"src":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/502b1/hero.png","srcSet":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/f2e6d/hero.png 114w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/4ddba/hero.png 229w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/502b1/hero.png 457w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/7ddc2/hero.png 686w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/435bf/hero.png 914w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/f5a68/hero.png 2036w","srcWebp":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/15384/hero.webp","srcSetWebp":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/31fce/hero.webp 114w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/e3e25/hero.webp 229w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/15384/hero.webp 457w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/0258d/hero.webp 686w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/64ea2/hero.webp 914w,\n/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/903d5/hero.webp 2036w","sizes":"(max-width: 457px) 100vw, 457px"},"seo":{"src":"/blog/static/02aee0b8e48b73dc6ae84f46ca80fea3/6050d/hero.png"}}}]}}}